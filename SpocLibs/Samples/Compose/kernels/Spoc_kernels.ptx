	.version 1.4
	.target sm_13
	// compiled with C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v4.1\bin/../open64/lib//be.exe
	// nvopencc 4.1 built on 2011-11-18

	//-----------------------------------------------------------
	// Compiling C:/cygwin/tmp/tmpxft_00002dd4_00000000-11_Spoc_kernels.cpp3.i (C:/Users/MATHIA~1/AppData/Local/Temp/ccBI#.a13224)
	//-----------------------------------------------------------

	//-----------------------------------------------------------
	// Options:
	//-----------------------------------------------------------
	//  Target:ptx, ISA:sm_13, Endian:little, Pointer Size:64
	//  -O3	(Optimization level)
	//  -g0	(Debug level)
	//  -m2	(Report advisories)
	//-----------------------------------------------------------

	.file	1	"C:/cygwin/tmp/tmpxft_00002dd4_00000000-10_Spoc_kernels.cudafe2.gpu"
	.file	2	"c:\program files (x86)\microsoft visual studio 10.0\vc\include\codeanalysis\sourceannotations.h"
	.file	3	"C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v4.1\bin/../include\crt/device_runtime.h"
	.file	4	"C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v4.1\bin/../include\host_defines.h"
	.file	5	"C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v4.1\bin/../include\builtin_types.h"
	.file	6	"c:\program files\nvidia gpu computing toolkit\cuda\v4.1\include\device_types.h"
	.file	7	"c:\program files\nvidia gpu computing toolkit\cuda\v4.1\include\host_defines.h"
	.file	8	"c:\program files\nvidia gpu computing toolkit\cuda\v4.1\include\driver_types.h"
	.file	9	"c:\program files\nvidia gpu computing toolkit\cuda\v4.1\include\surface_types.h"
	.file	10	"c:\program files\nvidia gpu computing toolkit\cuda\v4.1\include\texture_types.h"
	.file	11	"c:\program files\nvidia gpu computing toolkit\cuda\v4.1\include\vector_types.h"
	.file	12	"c:\program files\nvidia gpu computing toolkit\cuda\v4.1\include\builtin_types.h"
	.file	13	"C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v4.1\bin/../include\device_launch_parameters.h"
	.file	14	"c:\program files\nvidia gpu computing toolkit\cuda\v4.1\include\crt\storage_class.h"
	.file	15	"kernels/Spoc_kernels.cu"
	.file	16	"C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v4.1\bin/../include\common_functions.h"
	.file	17	"c:\program files\nvidia gpu computing toolkit\cuda\v4.1\include\math_functions.h"
	.file	18	"c:\program files\nvidia gpu computing toolkit\cuda\v4.1\include\math_constants.h"
	.file	19	"c:\program files\nvidia gpu computing toolkit\cuda\v4.1\include\device_functions.h"
	.file	20	"c:\program files\nvidia gpu computing toolkit\cuda\v4.1\include\sm_11_atomic_functions.h"
	.file	21	"c:\program files\nvidia gpu computing toolkit\cuda\v4.1\include\sm_12_atomic_functions.h"
	.file	22	"c:\program files\nvidia gpu computing toolkit\cuda\v4.1\include\sm_13_double_functions.h"
	.file	23	"c:\program files\nvidia gpu computing toolkit\cuda\v4.1\include\sm_20_atomic_functions.h"
	.file	24	"c:\program files\nvidia gpu computing toolkit\cuda\v4.1\include\sm_20_intrinsics.h"
	.file	25	"c:\program files\nvidia gpu computing toolkit\cuda\v4.1\include\surface_functions.h"
	.file	26	"c:\program files\nvidia gpu computing toolkit\cuda\v4.1\include\texture_fetch_functions.h"
	.file	27	"c:\program files\nvidia gpu computing toolkit\cuda\v4.1\include\math_functions_dbl_ptx3.h"


	.entry vec_add (
		.param .u64 __cudaparm_vec_add_A,
		.param .u64 __cudaparm_vec_add_B,
		.param .u64 __cudaparm_vec_add_C,
		.param .s32 __cudaparm_vec_add_N)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<5>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<5>;
	.loc	15	42	0
$LDWbegin_vec_add:
	.loc	15	46	0
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	mul.wide.s32 	%rd2, %r3, 4;
	ld.param.u64 	%rd3, [__cudaparm_vec_add_A];
	add.u64 	%rd4, %rd3, %rd2;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_vec_add_B];
	add.u64 	%rd6, %rd5, %rd2;
	ld.global.f32 	%f2, [%rd6+0];
	add.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd7, [__cudaparm_vec_add_C];
	add.u64 	%rd8, %rd7, %rd2;
	st.global.f32 	[%rd8+0], %f3;
	.loc	15	47	0
	exit;
$LDWend_vec_add:
	} // vec_add

	.entry vec_mult (
		.param .u64 __cudaparm_vec_mult_A,
		.param .u64 __cudaparm_vec_mult_B,
		.param .u64 __cudaparm_vec_mult_C,
		.param .s32 __cudaparm_vec_mult_N)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<5>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<5>;
	.loc	15	49	0
$LDWbegin_vec_mult:
	.loc	15	53	0
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	mul.wide.s32 	%rd2, %r3, 4;
	ld.param.u64 	%rd3, [__cudaparm_vec_mult_A];
	add.u64 	%rd4, %rd3, %rd2;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_vec_mult_B];
	add.u64 	%rd6, %rd5, %rd2;
	ld.global.f32 	%f2, [%rd6+0];
	mul.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd7, [__cudaparm_vec_mult_C];
	add.u64 	%rd8, %rd7, %rd2;
	st.global.f32 	[%rd8+0], %f3;
	.loc	15	54	0
	exit;
$LDWend_vec_mult:
	} // vec_mult

	.entry vec_div (
		.param .u64 __cudaparm_vec_div_A,
		.param .u64 __cudaparm_vec_div_B,
		.param .u64 __cudaparm_vec_div_C,
		.param .s32 __cudaparm_vec_div_N)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<5>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<5>;
	.loc	15	56	0
$LDWbegin_vec_div:
	.loc	15	60	0
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	mul.wide.s32 	%rd2, %r3, 4;
	ld.param.u64 	%rd3, [__cudaparm_vec_div_A];
	add.u64 	%rd4, %rd3, %rd2;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_vec_div_B];
	add.u64 	%rd6, %rd5, %rd2;
	ld.global.f32 	%f2, [%rd6+0];
	div.full.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd7, [__cudaparm_vec_div_C];
	add.u64 	%rd8, %rd7, %rd2;
	st.global.f32 	[%rd8+0], %f3;
	.loc	15	61	0
	exit;
$LDWend_vec_div:
	} // vec_div

	.entry vec_sub (
		.param .u64 __cudaparm_vec_sub_A,
		.param .u64 __cudaparm_vec_sub_B,
		.param .u64 __cudaparm_vec_sub_C,
		.param .s32 __cudaparm_vec_sub_N)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<5>;
	.reg .u64 %rd<10>;
	.reg .f32 %f<5>;
	.loc	15	63	0
$LDWbegin_vec_sub:
	.loc	15	67	0
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	mul.wide.s32 	%rd2, %r3, 4;
	ld.param.u64 	%rd3, [__cudaparm_vec_sub_A];
	add.u64 	%rd4, %rd3, %rd2;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_vec_sub_B];
	add.u64 	%rd6, %rd5, %rd2;
	ld.global.f32 	%f2, [%rd6+0];
	sub.f32 	%f3, %f1, %f2;
	ld.param.u64 	%rd7, [__cudaparm_vec_sub_C];
	add.u64 	%rd8, %rd7, %rd2;
	st.global.f32 	[%rd8+0], %f3;
	.loc	15	68	0
	exit;
$LDWend_vec_sub:
	} // vec_sub

	.entry vec_fma (
		.param .u64 __cudaparm_vec_fma_A,
		.param .u64 __cudaparm_vec_fma_B,
		.param .u64 __cudaparm_vec_fma_C,
		.param .u64 __cudaparm_vec_fma_D,
		.param .s32 __cudaparm_vec_fma_N)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<5>;
	.reg .u64 %rd<12>;
	.reg .f32 %f<6>;
	.loc	15	71	0
$LDWbegin_vec_fma:
	.loc	15	75	0
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	mul.wide.s32 	%rd2, %r3, 4;
	ld.param.u64 	%rd3, [__cudaparm_vec_fma_A];
	add.u64 	%rd4, %rd3, %rd2;
	ld.global.f32 	%f1, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_vec_fma_B];
	add.u64 	%rd6, %rd5, %rd2;
	ld.global.f32 	%f2, [%rd6+0];
	ld.param.u64 	%rd7, [__cudaparm_vec_fma_C];
	add.u64 	%rd8, %rd7, %rd2;
	ld.global.f32 	%f3, [%rd8+0];
	mad.f32 	%f4, %f2, %f3, %f1;
	ld.param.u64 	%rd9, [__cudaparm_vec_fma_D];
	add.u64 	%rd10, %rd9, %rd2;
	st.global.f32 	[%rd10+0], %f4;
	.loc	15	76	0
	exit;
$LDWend_vec_fma:
	} // vec_fma

	.entry vec_add_64 (
		.param .u64 __cudaparm_vec_add_64_A,
		.param .u64 __cudaparm_vec_add_64_B,
		.param .u64 __cudaparm_vec_add_64_C,
		.param .s32 __cudaparm_vec_add_64_N)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<5>;
	.reg .u64 %rd<10>;
	.reg .f64 %fd<5>;
	.loc	15	79	0
$LDWbegin_vec_add_64:
	.loc	15	83	0
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	cvt.s64.s32 	%rd1, %r3;
	mul.wide.s32 	%rd2, %r3, 8;
	ld.param.u64 	%rd3, [__cudaparm_vec_add_64_A];
	add.u64 	%rd4, %rd3, %rd2;
	ld.global.f64 	%fd1, [%rd4+0];
	ld.param.u64 	%rd5, [__cudaparm_vec_add_64_B];
	add.u64 	%rd6, %rd5, %rd2;
	ld.global.f64 	%fd2, [%rd6+0];
	add.f64 	%fd3, %fd1, %fd2;
	ld.param.u64 	%rd7, [__cudaparm_vec_add_64_C];
	add.u64 	%rd8, %rd7, %rd2;
	st.global.f64 	[%rd8+0], %fd3;
	.loc	15	84	0
	exit;
$LDWend_vec_add_64:
	} // vec_add_64

	.entry sum (
		.param .u64 __cudaparm_sum_vec1,
		.param .u64 __cudaparm_sum_result,
		.param .u64 __cudaparm_sum_tmp1,
		.param .s32 __cudaparm_sum_count)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<29>;
	.reg .u64 %rd<20>;
	.reg .pred %p<7>;
	.loc	15	91	0
$LDWbegin_sum:
	ld.param.s32 	%r1, [__cudaparm_sum_count];
	shr.s32 	%r2, %r1, 31;
	mov.s32 	%r3, 1;
	and.b32 	%r4, %r2, %r3;
	add.s32 	%r5, %r4, %r1;
	shr.s32 	%r6, %r5, 1;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r7, %rh1, %rh2;
	cvt.u32.u16 	%r8, %tid.x;
	add.u32 	%r9, %r8, %r7;
	setp.le.s32 	%p1, %r6, %r9;
	@%p1 bra 	$Lt_6_3586;
	.loc	15	97	0
	cvt.s64.s32 	%rd1, %r9;
	mul.wide.s32 	%rd2, %r9, 4;
	ld.param.u64 	%rd3, [__cudaparm_sum_vec1];
	add.u64 	%rd4, %rd2, %rd3;
	ld.global.s32 	%r10, [%rd4+0];
	add.s32 	%r11, %r6, %r9;
	cvt.s64.s32 	%rd5, %r11;
	mul.wide.s32 	%rd6, %r11, 4;
	add.u64 	%rd7, %rd3, %rd6;
	ld.global.s32 	%r12, [%rd7+0];
	add.s32 	%r13, %r10, %r12;
	ld.param.u64 	%rd8, [__cudaparm_sum_tmp1];
	add.u64 	%rd9, %rd8, %rd2;
	st.global.s32 	[%rd9+0], %r13;
$Lt_6_3586:
	.loc	15	98	0
	bar.sync 	0;
	.loc	15	100	0
	shr.s32 	%r14, %r6, 31;
	mov.s32 	%r15, 1;
	and.b32 	%r16, %r14, %r15;
	add.s32 	%r17, %r16, %r6;
	shr.s32 	%r18, %r17, 1;
	mov.s32 	%r19, %r18;
	mov.u32 	%r20, 0;
	setp.eq.u32 	%p2, %r18, %r20;
	@%p2 bra 	$Lt_6_4098;
$Lt_6_4610:
	setp.ge.u32 	%p3, %r9, %r19;
	@%p3 bra 	$Lt_6_4866;
	.loc	15	103	0
	cvt.s64.s32 	%rd10, %r9;
	mul.wide.s32 	%rd11, %r9, 4;
	ld.param.u64 	%rd12, [__cudaparm_sum_tmp1];
	add.u64 	%rd13, %rd11, %rd12;
	ld.global.s32 	%r21, [%rd13+0];
	add.u32 	%r22, %r9, %r19;
	cvt.u64.u32 	%rd14, %r22;
	mul.wide.u32 	%rd15, %r22, 4;
	add.u64 	%rd16, %rd12, %rd15;
	ld.global.s32 	%r23, [%rd16+0];
	add.s32 	%r24, %r21, %r23;
	st.global.s32 	[%rd13+0], %r24;
$Lt_6_4866:
	.loc	15	104	0
	bar.sync 	0;
	.loc	15	100	0
	shr.u32 	%r19, %r19, 1;
	mov.u32 	%r25, 0;
	setp.ne.u32 	%p4, %r19, %r25;
	@%p4 bra 	$Lt_6_4610;
$Lt_6_4098:
	mov.u32 	%r26, 0;
	setp.ne.s32 	%p5, %r9, %r26;
	@%p5 bra 	$Lt_6_5634;
	.loc	15	107	0
	ld.param.u64 	%rd17, [__cudaparm_sum_tmp1];
	ld.global.s32 	%r27, [%rd17+0];
	ld.param.u64 	%rd18, [__cudaparm_sum_result];
	st.global.s32 	[%rd18+0], %r27;
$Lt_6_5634:
	.loc	15	108	0
	exit;
$LDWend_sum:
	} // sum

	.entry spoc_max (
		.param .u64 __cudaparm_spoc_max_input,
		.param .u64 __cudaparm_spoc_max_output,
		.param .s32 __cudaparm_spoc_max_size)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<11>;
	.reg .u64 %rd<5>;
	.reg .f64 %fd<6>;
	.reg .pred %p<6>;
	.loc	15	111	0
$LDWbegin_spoc_max:
	cvt.u32.u16 	%r1, %tid.x;
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r2, %rh1, %rh2;
	add.u32 	%r3, %r1, %r2;
	mov.u32 	%r4, 0;
	setp.le.s32 	%p1, %r3, %r4;
	@%p1 bra 	$Lt_7_2818;
	bra.uni 	$LBB10_spoc_max;
$Lt_7_2818:
	.loc	15	115	0
	ld.param.u64 	%rd1, [__cudaparm_spoc_max_input];
	ld.global.f64 	%fd1, [%rd1+0];
	abs.f64 	%fd2, %fd1;
	ld.param.s32 	%r5, [__cudaparm_spoc_max_size];
	mov.u32 	%r6, 1;
	setp.le.s32 	%p2, %r5, %r6;
	@%p2 bra 	$Lt_7_3330;
	ld.param.s32 	%r5, [__cudaparm_spoc_max_size];
	sub.s32 	%r7, %r5, 1;
	ld.param.u64 	%rd1, [__cudaparm_spoc_max_input];
	add.u64 	%rd2, %rd1, 8;
	mov.s32 	%r8, 1;
	mov.s32 	%r9, %r7;
$Lt_7_3842:
 //<loop> Loop body line 115, nesting depth: 1, estimated iterations: unknown
	ld.global.f64 	%fd3, [%rd2+0];
	abs.f64 	%fd4, %fd3;
	setp.gt.f64 	%p3, %fd4, %fd2;
	@!%p3 bra 	$Lt_7_4098;
	.loc	15	119	0
	mov.f64 	%fd2, %fd4;
$Lt_7_4098:
	add.s32 	%r8, %r8, 1;
	add.u64 	%rd2, %rd2, 8;
	.loc	15	115	0
	ld.param.s32 	%r5, [__cudaparm_spoc_max_size];
	.loc	15	119	0
	setp.ne.s32 	%p4, %r5, %r8;
	@%p4 bra 	$Lt_7_3842;
$Lt_7_3330:
	.loc	15	121	0
	ld.param.u64 	%rd3, [__cudaparm_spoc_max_output];
	st.global.f64 	[%rd3+0], %fd2;
$LBB10_spoc_max:
	.loc	15	122	0
	exit;
$LDWend_spoc_max:
	} // spoc_max

	.entry int_bubble_filter (
		.param .u64 __cudaparm_int_bubble_filter_input,
		.param .u64 __cudaparm_int_bubble_filter_vec1,
		.param .u64 __cudaparm_int_bubble_filter_output,
		.param .s32 __cudaparm_int_bubble_filter_count)
	{
	.reg .u16 %rh<4>;
	.reg .u32 %r<36>;
	.reg .u64 %rd<15>;
	.reg .pred %p<9>;
	.loc	15	128	0
$LDWbegin_int_bubble_filter:
	mov.u16 	%rh1, %ctaid.x;
	mov.u16 	%rh2, %ntid.x;
	mul.wide.u16 	%r1, %rh1, %rh2;
	cvt.u32.u16 	%r2, %tid.x;
	add.u32 	%r3, %r2, %r1;
	ld.param.s32 	%r4, [__cudaparm_int_bubble_filter_count];
	shr.s32 	%r5, %r4, 31;
	mov.s32 	%r6, 1;
	and.b32 	%r7, %r5, %r6;
	add.s32 	%r8, %r7, %r4;
	shr.s32 	%r9, %r8, 1;
	setp.gt.s32 	%p1, %r3, %r9;
	@%p1 bra 	$Lt_8_6146;
	.loc	15	135	0
	mul.lo.s32 	%r10, %r3, 2;
	cvt.s64.s32 	%rd1, %r10;
	mul.wide.s32 	%rd2, %r10, 4;
	ld.param.u64 	%rd3, [__cudaparm_int_bubble_filter_vec1];
	add.u64 	%rd4, %rd3, %rd2;
	ld.param.u64 	%rd5, [__cudaparm_int_bubble_filter_output];
	add.u64 	%rd6, %rd2, %rd5;
	ld.global.s32 	%r11, [%rd4+0];
	st.global.s32 	[%rd6+0], %r11;
	.loc	15	136	0
	ld.global.s32 	%r12, [%rd4+4];
	st.global.s32 	[%rd6+4], %r12;
	.loc	15	128	0
	ld.param.s32 	%r4, [__cudaparm_int_bubble_filter_count];
	.loc	15	136	0
	mul.lo.s32 	%r13, %r4, 2;
	mov.u32 	%r14, 0;
	setp.le.s32 	%p2, %r13, %r14;
	@%p2 bra 	$Lt_8_6658;
	mov.s32 	%r15, %r13;
	mov.s32 	%r16, 0;
	mov.s32 	%r17, 1;
	mov.s32 	%r18, %r15;
$Lt_8_7170:
 //<loop> Loop body line 136, nesting depth: 1, estimated iterations: unknown
	.loc	15	141	0
	mov.s32 	%r19, 0;
	set.eq.u32.s32 	%r20, %r17, %r19;
	neg.s32 	%r17, %r20;
	add.s32 	%r21, %r10, %r17;
	add.s32 	%r22, %r21, 1;
	setp.le.s32 	%p3, %r4, %r22;
	@%p3 bra 	$Lt_8_7426;
	.loc	15	145	0
	cvt.s64.s32 	%rd7, %r21;
	mul.wide.s32 	%rd8, %r21, 4;
	ld.param.u64 	%rd9, [__cudaparm_int_bubble_filter_input];
	add.u64 	%rd10, %rd9, %rd8;
	ld.global.s32 	%r23, [%rd10+0];
	mov.s32 	%r24, 0;
	setp.eq.s32 	%p4, %r23, %r24;
	@!%p4 bra 	$Lt_8_9474;
	ld.global.s32 	%r25, [%rd10+4];
	mov.u32 	%r26, 0;
	setp.eq.s32 	%p5, %r25, %r26;
	@%p5 bra 	$L_8_5634;
	.loc	15	147	0
	mov.s32 	%r27, 1;
	st.global.s32 	[%rd10+0], %r27;
	.loc	15	148	0
	mov.s32 	%r28, 0;
	st.global.s32 	[%rd10+4], %r28;
	.loc	15	149	0
	add.u64 	%rd11, %rd8, %rd5;
	ld.global.s32 	%r29, [%rd11+4];
	st.global.s32 	[%rd11+0], %r29;
	.loc	15	150	0
	mov.s32 	%r30, 0;
	st.global.s32 	[%rd11+4], %r30;
	bra.uni 	$L_8_5378;
$Lt_8_9474:
$L_8_5634:
	.loc	15	156	0
	@!%p4 bra 	$Lt_8_7938;
	.loc	15	155	0
	mov.s32 	%r31, 0;
	add.u64 	%rd12, %rd8, %rd5;
	st.global.s32 	[%rd12+0], %r31;
$Lt_8_7938:
	ld.global.s32 	%r32, [%rd10+4];
	mov.u32 	%r33, 0;
	setp.ne.s32 	%p6, %r32, %r33;
	@%p6 bra 	$Lt_8_8450;
	.loc	15	157	0
	mov.s32 	%r34, 0;
	add.u64 	%rd13, %rd8, %rd5;
	st.global.s32 	[%rd13+4], %r34;
$Lt_8_8450:
$L_8_5378:
$Lt_8_7426:
	.loc	15	160	0
	bar.sync 	0;
	add.s32 	%r16, %r16, 1;
	setp.ne.s32 	%p7, %r13, %r16;
	@%p7 bra 	$Lt_8_7170;
$Lt_8_6658:
$Lt_8_6146:
	.loc	15	163	0
	exit;
$LDWend_int_bubble_filter:
	} // int_bubble_filter

