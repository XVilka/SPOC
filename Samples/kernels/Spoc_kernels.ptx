//
// Generated by NVIDIA NVVM Compiler
// Compiler built on Fri Jun 20 02:24:09 2014 (1403223849)
// Cuda compilation tools, release 6.5, V6.5.10
//

.version 4.1
.target sm_20
.address_size 64


.visible .entry vec_add(
	.param .u64 vec_add_param_0,
	.param .u64 vec_add_param_1,
	.param .u64 vec_add_param_2,
	.param .u32 vec_add_param_3
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<4>;
	.reg .s32 	%r<6>;
	.reg .s64 	%rd<11>;


	ld.param.u64 	%rd1, [vec_add_param_0];
	ld.param.u64 	%rd2, [vec_add_param_1];
	ld.param.u64 	%rd3, [vec_add_param_2];
	ld.param.u32 	%r2, [vec_add_param_3];
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %tid.x;
	mad.lo.s32 	%r1, %r3, %r4, %r5;
	setp.ge.s32	%p1, %r1, %r2;
	@%p1 bra 	BB0_2;

	cvta.to.global.u64 	%rd4, %rd3;
	cvta.to.global.u64 	%rd5, %rd2;
	cvta.to.global.u64 	%rd6, %rd1;
	mul.wide.s32 	%rd7, %r1, 4;
	add.s64 	%rd8, %rd6, %rd7;
	add.s64 	%rd9, %rd5, %rd7;
	ld.global.f32 	%f1, [%rd9];
	ld.global.f32 	%f2, [%rd8];
	add.f32 	%f3, %f2, %f1;
	add.s64 	%rd10, %rd4, %rd7;
	st.global.f32 	[%rd10], %f3;

BB0_2:
	ret;
}

.visible .entry vec_add_double(
	.param .u64 vec_add_double_param_0,
	.param .u64 vec_add_double_param_1,
	.param .u64 vec_add_double_param_2,
	.param .u32 vec_add_double_param_3
)
{
	.reg .pred 	%p<2>;
	.reg .s32 	%r<6>;
	.reg .s64 	%rd<11>;
	.reg .f64 	%fd<4>;


	ld.param.u64 	%rd1, [vec_add_double_param_0];
	ld.param.u64 	%rd2, [vec_add_double_param_1];
	ld.param.u64 	%rd3, [vec_add_double_param_2];
	ld.param.u32 	%r2, [vec_add_double_param_3];
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %tid.x;
	mad.lo.s32 	%r1, %r3, %r4, %r5;
	setp.ge.s32	%p1, %r1, %r2;
	@%p1 bra 	BB1_2;

	cvta.to.global.u64 	%rd4, %rd3;
	cvta.to.global.u64 	%rd5, %rd2;
	cvta.to.global.u64 	%rd6, %rd1;
	mul.wide.s32 	%rd7, %r1, 8;
	add.s64 	%rd8, %rd6, %rd7;
	add.s64 	%rd9, %rd5, %rd7;
	ld.global.f64 	%fd1, [%rd9];
	ld.global.f64 	%fd2, [%rd8];
	add.f64 	%fd3, %fd2, %fd1;
	add.s64 	%rd10, %rd4, %rd7;
	st.global.f64 	[%rd10], %fd3;

BB1_2:
	ret;
}


